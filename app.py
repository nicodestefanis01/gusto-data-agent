"""
Gusto Data Agent - Production
============================
AI-powered SQL generation for Gusto data warehouse with real database connectivity
"""

import streamlit as st
import pandas as pd
import os
import psycopg2
from datetime import datetime
from typing import Dict, List, Optional, Any
import json

# Load environment variables from .env file
from dotenv import load_dotenv
load_dotenv()

# Try to import OpenAI, fall back to mock if not available
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

st.set_page_config(page_title="Gusto Data Agent", page_icon="ğŸ¢", layout="wide")

# Real Gusto warehouse table schemas (discovered from actual database)
TABLE_SCHEMAS = {
    "bi.companies": {
        "description": "Core company information - use 'id' for company ID and 'name' for company name",
        "columns": ["id", "name", "trade_name", "accounting_firm_id", "created_at", "initial_company_size", "initial_employee_count", "approval_status", "number_active_employees", "number_active_contractors", "joined_at", "is_active", "filing_state", "filing_city", "filing_zip", "has_bank_info", "current_federal_deposit_schedule", "sales_program", "industry_classification", "user_provided_industry", "naics_code"]
    },
    "bi.credit_delinquencies": {
        "description": "Credit delinquency records - use company_id to join with companies",
        "columns": ["company_id", "name", "payment_id", "payment_type", "debit_date", "debit_amount_attempted", "error_code", "past_due_date", "successful_credits", "successful_debits", "is_credit_loss", "recovery_amount_needed", "recovered_amount", "delinquent_status", "days_past_due", "is_cancelled"]
    },
    "bi.gusto_employees": {
        "description": "Employee information - use 'id' for employee ID",
        "columns": ["id", "first_name", "last_name", "name", "email", "hired_at", "terminated_at", "department_name", "work_state", "status", "worker_type", "job_title", "location", "team", "is_pe", "current_flag"]
    },
    "bi_reporting.gusto_payments_and_losses": {
        "description": "Payment processing data and financial losses",
        "columns": ["calendar_date", "event_type", "company_id", "event_id", "event_debit_date", "bank_name", "company_age", "sales_program", "user_provided_industry", "product_plan", "initial_size", "current_size", "invoice_total_debit", "event_gross_amount", "credit_loss_flag", "days_past_due", "failed_payment_flag", "net_loss_amount"]
    },
    "bi.penalty_cases": {
        "description": "Penalty cases and compliance issues",
        "columns": ["id", "agent_id", "agency_name", "created_at", "year", "quarter", "title", "total_interest_amount", "error_type", "total_penalty_amount", "total_penalty_paid", "total_interest_paid", "error_origin", "status", "penalty_group_id"]
    },
    "bi.penalty_groups": {
        "description": "Penalty group information",
        "columns": ["id", "penalty_case_id", "link", "ticket_system_of_record", "sor_ticket_id", "pay_to", "batch", "approval_status", "created_at"]
    },
    "bi.nacha_entries": {
        "description": "ACH/NACHA payment entries and processing data",
        "columns": ["id", "created_at_date", "amount", "company_id", "employee_id", "contractor_id", "payroll_id", "error_code", "is_debit", "is_credit", "entry_code", "transaction_type", "is_invoice", "bank_account_type", "processing_state", "effective_entry_date"]
    },
    "bi.company_approval_details": {
        "description": "Company approval status and risk information",
        "columns": ["id", "company_id", "approved_by_id", "approved_by_system", "first_approved_at", "last_rejected_at", "approval_status", "ready_for_approval", "risk_state", "risk_state_description", "auto_approval_blockers"]
    },
    "bi.monthly_companies": {
        "description": "Monthly company metrics and revenue data",
        "columns": ["company_id", "for_month", "product_plan", "pricing_plan", "number_of_paid_payrolls", "is_churned", "total_subscription_revenue", "total_revenue", "total_payroll_revenue", "company_size", "company_size_segment", "number_of_payroll_employees", "number_of_payroll_contractors", "number_of_cases", "multistate_flag"]
    },
    "bi.user_roles": {
        "description": "User roles and permissions",
        "columns": ["id", "user_id", "type", "employee_id", "company_id", "accounting_firm_id", "contractor_id", "created_at"]
    },
    "bi_reporting.risk_operational_metrics": {
        "description": "Risk operational metrics and case data",
        "columns": ["for_date", "flow", "age", "sales_program", "initial_company_size", "is_gep_company", "is_mrb", "model_triggered", "case_type", "count_of_cases", "total_active_customers", "time_spent_in_mins"]
    },
    "bi_reporting.risk_review_data": {
        "description": "Risk review activity data",
        "columns": ["calendar_date", "reviewed_by_email", "reviewer", "event_timestamp", "company_id", "review_type", "old_review_status", "new_review_status"]
    },
    "bi.sfdc_tickets": {
        "description": "Salesforce ticket data",
        "columns": ["sfdc_ticket_id", "sfdc_owner_id", "owner_role", "created_ts", "closed_ts"]
    },
    "bi.cases": {
        "description": "Support cases and tickets",
        "columns": ["casenumber", "id", "trimmed_case_id", "parent_case", "zendesk_id"]
    }
}

class RedshiftConnection:
    """Handles connections to Redshift database"""
    
    def __init__(self):
        self.host = os.getenv("REDSHIFT_HOST")
        self.database = os.getenv("REDSHIFT_DATABASE") 
        self.user = os.getenv("REDSHIFT_USERNAME")
        self.password = os.getenv("REDSHIFT_PASSWORD")
        self.port = int(os.getenv("REDSHIFT_PORT", 5439))
        self.conn = None
        self._connection_tested = False
        self._connection_works = False
        
    def is_configured(self) -> bool:
        """Check if all required credentials are available"""
        return all([self.host, self.database, self.user, self.password])
    
    def test_connection(self) -> bool:
        """Test connection to Redshift (with timeout and error handling)"""
        if self._connection_tested:
            return self._connection_works
            
        if not self.is_configured():
            self._connection_tested = True
            self._connection_works = False
            return False
            
        try:
            # Use a shorter timeout for public deployments
            conn = psycopg2.connect(
                host=self.host,
                database=self.database,
                user=self.user,
                password=self.password,
                port=self.port,
                connect_timeout=10  # 10 second timeout
            )
            conn.close()
            self._connection_tested = True
            self._connection_works = True
            return True
        except Exception as e:
            self._connection_tested = True
            self._connection_works = False
            # Store the error for debugging
            self._connection_error = str(e)
            return False
    
    def connect(self) -> bool:
        """Establish connection to Redshift"""
        if not self.test_connection():
            return False
            
        try:
            self.conn = psycopg2.connect(
                host=self.host,
                database=self.database,
                user=self.user,
                password=self.password,
                port=self.port,
                connect_timeout=10
            )
            return True
        except Exception as e:
            return False
    
    def execute_query(self, sql: str) -> Dict[str, Any]:
        """Execute SQL query and return results"""
        if not self.connect():
            return {"success": False, "error": "Database connection failed"}
        
        try:
            cursor = self.conn.cursor()
            start_time = datetime.now()
            cursor.execute(sql)
            
            # Fetch results
            columns = [desc[0] for desc in cursor.description] if cursor.description else []
            rows = cursor.fetchall()
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # Convert to list of dictionaries
            data = [dict(zip(columns, row)) for row in rows]
            
            return {
                "success": True,
                "data": data,
                "row_count": len(data),
                "execution_time_seconds": execution_time
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
        finally:
            if cursor:
                cursor.close()

class SQLGenerator:
    """Generates SQL queries using OpenAI"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if self.api_key and OPENAI_AVAILABLE:
            self.client = OpenAI(api_key=self.api_key)
            self.available = True
        else:
            self.available = False
    
    def generate_sql(self, natural_query: str) -> Dict[str, Any]:
        """Generate SQL from natural language query"""
        if not self.available:
            return self._mock_sql_generation(natural_query)
        
        try:
            # Create the prompt for OpenAI
            system_prompt = f"""You are a SQL expert for Gusto's data warehouse. Generate Redshift-compatible SQL queries.

Available tables and their purposes:
{json.dumps(TABLE_SCHEMAS, indent=2)}

Rules:
1. Only use tables from the schema above
2. Use Redshift/PostgreSQL syntax
3. Always include LIMIT clauses to prevent large result sets
4. Use proper JOINs when combining tables
5. Return only the SQL query, no explanations

Generate a SQL query for: {natural_query}"""

            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": system_prompt}],
                max_tokens=500,
                temperature=0.1
            )
            
            sql_query = response.choices[0].message.content.strip()
            # Remove markdown code blocks if present
            if sql_query.startswith("```sql"):
                sql_query = sql_query[6:-3]
            elif sql_query.startswith("```"):
                sql_query = sql_query[3:-3]
            
            return {
                "success": True,
                "sql": sql_query,
                "explanation": f"AI-generated SQL for: {natural_query}"
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _mock_sql_generation(self, query: str) -> Dict[str, Any]:
        """Fallback mock SQL generation when OpenAI is not available"""
        q = query.lower()
        
        if "credit delinquencies" in q and "30 days" in q:
            sql = """SELECT c.name AS company_name, c.filing_state, cd.debit_date, cd.debit_amount_attempted, cd.delinquent_status
FROM bi.companies c
JOIN bi.credit_delinquencies cd ON c.id = cd.company_id
WHERE cd.debit_date >= CURRENT_DATE - INTERVAL '30 days'
ORDER BY cd.debit_date DESC
LIMIT 100;"""
        elif "employee count" in q:
            sql = """SELECT name AS company_name, filing_state, number_active_employees
FROM bi.companies
WHERE number_active_employees IS NOT NULL
ORDER BY number_active_employees DESC
LIMIT 20;"""
        elif "california" in q or "risk" in q:
            sql = """SELECT c.name AS company_name, c.filing_state, COUNT(cd.company_id) AS risk_score
FROM bi.companies c
LEFT JOIN bi.credit_delinquencies cd ON c.id = cd.company_id
WHERE c.filing_state = 'CA'
GROUP BY c.id, c.name, c.filing_state
ORDER BY risk_score DESC
LIMIT 50;"""
        elif "penalty" in q:
            sql = """SELECT c.name AS company_name, pc.agency_name, pc.total_penalty_amount, pc.status
FROM bi.companies c
JOIN bi.penalty_cases pc ON c.id = pc.agent_id
WHERE pc.total_penalty_amount > 0
ORDER BY pc.total_penalty_amount DESC
LIMIT 50;"""
        else:
            sql = """SELECT name AS company_name, filing_state, number_active_employees
FROM bi.companies
WHERE is_active = true
LIMIT 100;"""
        
        return {
            "success": True,
            "sql": sql,
            "explanation": f"Template SQL generated for: {query} (using real Gusto schema)"
        }

def generate_realistic_demo_data(sql: str, query: str) -> List[Dict]:
    """Generate realistic demo data based on the SQL and query"""
    q = query.lower()
    
    if "credit delinquencies" in q or "delinquent" in sql.lower():
        return [
            {"company_name": "TechStart Solutions", "filing_state": "CA", "debit_date": "2024-01-15", "debit_amount_attempted": 15000, "delinquent_status": "Active"},
            {"company_name": "DataFlow Analytics", "filing_state": "NY", "debit_date": "2024-01-12", "debit_amount_attempted": 8500, "delinquent_status": "Active"},
            {"company_name": "CloudOps Systems", "filing_state": "TX", "debit_date": "2024-01-08", "debit_amount_attempted": 12750, "delinquent_status": "Resolved"},
            {"company_name": "InnovateTech Corp", "filing_state": "CA", "debit_date": "2024-01-05", "debit_amount_attempted": 22000, "delinquent_status": "Active"},
            {"company_name": "GreenField Logistics", "filing_state": "FL", "debit_date": "2024-01-03", "debit_amount_attempted": 5200, "delinquent_status": "Active"}
        ]
    elif "employee" in q or "number_active_employees" in sql.lower():
        return [
            {"company_name": "MegaCorp Industries", "filing_state": "CA", "number_active_employees": 2847},
            {"company_name": "Global Tech Solutions", "filing_state": "NY", "number_active_employees": 1923},
            {"company_name": "Innovation Labs Inc", "filing_state": "TX", "number_active_employees": 1456},
            {"company_name": "Future Systems LLC", "filing_state": "WA", "number_active_employees": 891},
            {"company_name": "Dynamic Solutions", "filing_state": "FL", "number_active_employees": 743},
            {"company_name": "NextGen Technologies", "filing_state": "CA", "number_active_employees": 652},
            {"company_name": "Quantum Dynamics", "filing_state": "MA", "number_active_employees": 589},
            {"company_name": "Stellar Innovations", "filing_state": "CO", "number_active_employees": 401}
        ]
    elif "penalty" in q or "penalty_amount" in sql.lower():
        return [
            {"company_name": "Apex Manufacturing", "agency_name": "California EDD", "total_penalty_amount": 12500, "status": "Open"},
            {"company_name": "Metro Services LLC", "agency_name": "Texas TWC", "total_penalty_amount": 8900, "status": "Under Review"},
            {"company_name": "Pioneer Industries", "agency_name": "New York DOL", "total_penalty_amount": 15600, "status": "Resolved"},
            {"company_name": "Coastal Enterprises", "agency_name": "Florida DEO", "total_penalty_amount": 6750, "status": "Open"}
        ]
    elif "california" in q or "risk" in q:
        return [
            {"company_name": "Silicon Valley Startups", "filing_state": "CA", "risk_score": 3},
            {"company_name": "Bay Area Technologies", "filing_state": "CA", "risk_score": 2},
            {"company_name": "Los Angeles Media Co", "filing_state": "CA", "risk_score": 1},
            {"company_name": "San Diego Biotech", "filing_state": "CA", "risk_score": 0},
            {"company_name": "Sacramento Solutions", "filing_state": "CA", "risk_score": 0}
        ]
    else:
        return [
            {"company_name": "Acme Corporation", "filing_state": "CA", "number_active_employees": 245},
            {"company_name": "Demo Industries", "filing_state": "NY", "number_active_employees": 189},
            {"company_name": "Example LLC", "filing_state": "TX", "number_active_employees": 156},
            {"company_name": "Sample Solutions", "filing_state": "FL", "number_active_employees": 98},
            {"company_name": "Test Technologies", "filing_state": "WA", "number_active_employees": 67}
        ]

def check_system_status():
    """Check what systems are available (OpenAI, Redshift)"""
    db = RedshiftConnection()
    sql_gen = SQLGenerator()
    
    redshift_works = db.test_connection()
    
    return {
        "redshift_configured": db.is_configured(),
        "redshift_accessible": redshift_works,
        "openai_available": sql_gen.available,
        "demo_mode": not (redshift_works and sql_gen.available)
    }

# Main App
def main():
    st.title("ğŸ¢ Gusto Data Agent")
    st.subheader("AI-powered SQL generation for Gusto data warehouse")
    
    # Check system status
    status = check_system_status()
    
    # Display status banner
    if status["redshift_accessible"] and status["openai_available"]:
        st.success("âœ… **Full Production Mode**: Connected to Redshift with AI-powered SQL generation")
    elif status["openai_available"] and not status["redshift_accessible"]:
        st.info("ğŸ¯ **AI Demo Mode**: OpenAI-powered SQL generation with realistic sample data (Redshift accessible only from internal network)")
    elif status["redshift_accessible"] and not status["openai_available"]:
        st.warning("âš ï¸ **Database Mode**: Connected to Redshift with template SQL generation")
    else:
        st.info("ğŸ® **Demo Mode**: Template SQL with sample data for sharing and demonstration")
    
    # Configuration sidebar
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        st.subheader("ğŸ“Š Database Status")
        if status["redshift_configured"]:
            if status["redshift_accessible"]:
                st.success("âœ… Redshift connected")
            else:
                st.warning("âš ï¸ Redshift configured but not accessible")
                st.info("ğŸ’¡ Database may only be accessible from internal network")
        else:
            st.error("âŒ Redshift not configured")
        
        st.subheader("ğŸ¤– AI Status") 
        if status["openai_available"]:
            st.success("âœ… OpenAI connected")
        else:
            st.error("âŒ OpenAI not configured")
        
        st.subheader("ğŸ—„ï¸ Available Tables")
        for table_name in list(TABLE_SCHEMAS.keys())[:8]:  # Show first 8 tables
            st.text(f"â€¢ {table_name}")
        if len(TABLE_SCHEMAS) > 8:
            st.text(f"... and {len(TABLE_SCHEMAS) - 8} more")
        
        if not status["redshift_accessible"]:
            st.markdown("---")
            st.info("ğŸ” **For Internal Use**: Connect to Gusto VPN for full database access")
    
    # Main interface
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ’¬ Ask Your Data Question")
        
        # Example queries
        examples = [
            "Show me all companies with credit delinquencies in the last 30 days",
            "List top 20 companies by employee count", 
            "Find companies in California with risk scores",
            "Show companies with penalty cases and amounts",
            "List recent payment activity by company"
        ]
        
        for i, example in enumerate(examples):
            if st.button(f"ğŸ“ {example}", key=f"example_{i}"):
                st.session_state.query = example
        
        # Query input
        query = st.text_area(
            "Enter your question:",
            value=st.session_state.get('query', ''),
            placeholder="e.g., Show me companies with credit delinquencies in the last 30 days",
            height=100
        )
        
        if st.button("ğŸš€ Generate SQL & Execute", type="primary"):
            if query:
                with st.spinner("Generating SQL..."):
                    # Generate SQL
                    sql_gen = SQLGenerator()
                    result = sql_gen.generate_sql(query)
                    
                    if result["success"]:
                        st.subheader("ğŸ“ Generated SQL")
                        st.code(result["sql"], language="sql")
                        
                        # Execute query
                        with st.spinner("Executing query..."):
                            if status["redshift_accessible"]:
                                # Use real database
                                db = RedshiftConnection()
                                exec_result = db.execute_query(result["sql"])
                            else:
                                # Use realistic demo data
                                demo_data = generate_realistic_demo_data(result["sql"], query)
                                exec_result = {
                                    "success": True,
                                    "data": demo_data,
                                    "row_count": len(demo_data),
                                    "execution_time_seconds": 0.15
                                }
                        
                        if exec_result["success"]:
                            st.subheader("ğŸ“Š Results")
                            
                            # Display metrics
                            col_a, col_b, col_c = st.columns(3)
                            with col_a:
                                st.metric("Rows", exec_result["row_count"])
                            with col_b:
                                st.metric("Time", f"{exec_result['execution_time_seconds']:.2f}s")
                            with col_c:
                                if status["redshift_accessible"]:
                                    st.metric("Source", "Real Data")
                                else:
                                    st.metric("Source", "Demo Data")
                            
                            # Display data
                            if exec_result["data"]:
                                df = pd.DataFrame(exec_result["data"])
                                st.dataframe(df, use_container_width=True)
                                
                                # Download option
                                csv = df.to_csv(index=False)
                                filename = f"gusto_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                                st.download_button(
                                    label="ğŸ“¥ Download CSV",
                                    data=csv,
                                    file_name=filename,
                                    mime="text/csv"
                                )
                                
                                # Simple visualization
                                numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
                                if len(numeric_cols) > 0 and len(df) > 1:
                                    st.subheader("ğŸ“ˆ Quick Visualization")
                                    if len(numeric_cols) > 1:
                                        chart_col = st.selectbox("Select column to chart:", numeric_cols)
                                    else:
                                        chart_col = numeric_cols[0]
                                    
                                    if 'company_name' in df.columns:
                                        chart_data = df.set_index('company_name')[chart_col].head(10)
                                        st.bar_chart(chart_data)
                            else:
                                st.info("Query executed successfully but returned no results.")
                        else:
                            st.error(f"Query execution failed: {exec_result['error']}")
                    else:
                        st.error(f"SQL generation failed: {result['error']}")
            else:
                st.warning("Please enter a query")
    
    with col2:
        st.subheader("â„¹ï¸ About")
        st.markdown("""
        **Gusto Data Agent** converts natural language into SQL queries for analyzing Gusto warehouse data.
        
        **Features:**
        - ğŸ§  AI-powered SQL generation via OpenAI
        - ğŸ“Š Real Gusto warehouse table schemas  
        - ğŸ”— Database connectivity (when accessible)
        - ğŸ”’ Read-only database safety
        - ğŸ’¾ CSV export capabilities
        - ğŸ“ˆ Quick data visualizations
        """)
        
        if status["redshift_accessible"]:
            st.success("ğŸ¯ **Connected to real Gusto data!**")
        else:
            st.info("ğŸ® **Demo mode with realistic sample data**")
        
        st.subheader("ğŸš€ Key Benefits")
        benefits = [
            "ğŸš€ **No more manual SQL** for common requests",
            "ğŸ“Š **Instant data access** for analysts", 
            "ğŸ‘¥ **Shareable interface** for team collaboration",
            "ğŸ”’ **Safe read-only** warehouse access"
        ]
        for benefit in benefits:
            st.markdown(f"- {benefit}")

if __name__ == "__main__":
    main() 